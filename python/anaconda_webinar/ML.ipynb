{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lmlg6iuLRGOq",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"logo.png\" align=\"right\" width=\"40%\"/>\n",
    "\n",
    "# Machine Learning with Scikit-learn\n",
    "\n",
    "<b>David Mertz, Ph.D.<br/> Anaconda Inc</b>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this Notebook\n",
    "\n",
    "What you are looking at now is a \"public deployment\" on Anaconda Enterprise.  It is a notebook—but a web application or dashboard can equally be published this way—that has been set to world readable (and world-executable, albeit without modifications to the code).\n",
    "\n",
    "Licensed users of [Anaconda Enterprise](https://www.anaconda.com/blog/developer-blog/anaconda-enterprise-features-expanded-gpu-container-usage/) can collaborate on development of projects, deploy them privately for a specific collection of users or user groups, target specific computational resources in their cluster, and schedule computational work utilized by projects.\n",
    "\n",
    "For this particular notebook that you can run, not a lot will change each time you run it.  A few of the models trained have a random seed that will produce somewhat different results across runs.  But in a real use, a cell of a notebook might, for example, pull in up-to-date data that is then analyzed and visualized within a Jupyter notebook like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MDeKgDqYRGOr"
   },
   "source": [
    "# Who am I?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VCf07leKRGOs"
   },
   "source": [
    "*August 2018*\n",
    "\n",
    "David was a Director of the PSF for six years, and remains co-chair of its Trademarks Committee,  its Python-Cuba working group, and of the Scientific Python Working Group. Nowadays he is Senior Trainer and Senior Software Developer for Anaconda Inc.\n",
    "\n",
    "He wrote the columns, _Charming Python_ and _XML Matters_ for IBM developerWorks, short books for O'Reilly, and the Addison-Wesley book _Text Processing in Python_, has spoken at multiple OSCon's,  PyCon's, and at AnacondaCon, and was invited keynote speaker at PyCon-India, PyCon-UK, PyCon-ZA, PyCon Belarus, PyCon Cuba, and PyData SF.\n",
    "\n",
    "Before Anaconda, David worked for 8 years with the folks (D. E. Shaw Research) who have built the world's fastest, highly-specialized (down to the ASICs and network layer), supercomputer for performing molecular dynamics.  He is pleased to find Python has become the default high-level language for most scientific computing projects.\n",
    "\n",
    "The latest version of this blurb will stay in a [Gist](https://gist.github.com/DavidMertz/e889b5d56008eb897cf9af73510c1901)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9QdJeJnHRGOs"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KAkXO_n0RGOu"
   },
   "source": [
    "# What is Anaconda?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CbRpDwITRGOu"
   },
   "source": [
    "Anaconda Inc is known as the creator of the Anaconda Distribution, Anaconda Enterprise, and as contributor or main sponsor of open source projects (some listed below): \n",
    "\n",
    "**Anaconda Distribution**\n",
    "\n",
    "> With over 6 million users, the open source Anaconda Distribution is the fastest and easiest way to do Python and R data science and machine learning on Linux, Windows, and Mac OS X. It's the industry standard for developing, testing, and training on a single machine.\n",
    "\n",
    "**Anaconda Enterprise**\n",
    "\n",
    "> Anaconda Enterprise is an AI/ML enablement platform that empowers organizations to develop, govern, and automate AI/ML and data science from laptop through training to production. It lets organizations scale from individual data scientists to collaborative teams of thousands, and to go from a single server to thousands of nodes for model training and deployment.\n",
    "\n",
    "**Open Source Projects**\n",
    "\n",
    "* *[Conda](https://conda.io/docs/)*\n",
    "* *[Dask](https://dask.pydata.org/en/latest/)*\n",
    "* *[Dask-ML](https://dask-ml.readthedocs.io/en/latest/)*\n",
    "* *[Numba](https://numba.pydata.org/)*\n",
    "* *[Bokeh](https://bokeh.pydata.org/en/latest/)*\n",
    "* *[DataShader](http://datashader.org/)*\n",
    "* *[Intake](https://intake.readthedocs.io/en/latest/quickstart.html)*\n",
    "* *[HoloViews](http://holoviews.org/)*\n",
    "* *[PyViz](http://pyviz.org/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SJ-bCcTIRGOv"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AfVB1cwhRGOv"
   },
   "source": [
    "# What is *scikit-learn*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yVSj34unRGOv"
   },
   "source": [
    "Scikit-learn provides a large range of algorithms in machine learning that are unified under a common and intuitive API.  Most of the dozens of classes provided for various kinds of models share the large majority of the same calling interface.  Very often—as we will see in examples below—you can easily substitute one algorithm for another with nearly no change in your underlying code.  This allows you to explore the problem space quickly, and often arrive at an optimal, or at least *satisficing* approach to your problem domain or datasets.\n",
    "\n",
    "* Simple and efficient tools for data mining and data analysis\n",
    "* Accessible to everybody, and reusable in various contexts\n",
    "* Built on *NumPy*, *SciPy*, and *matplotlib*\n",
    "* Open source, commercially usable - BSD license"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SV0q2IU3RGOw"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VOeBs1kCRGOx"
   },
   "source": [
    "# What is Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QF3juyp0RGOz"
   },
   "source": [
    "According to Wikipedia on [16:57, 4 August 2018](https://en.wikipedia.org/w/index.php?title=Machine_learning&oldid=853415971)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pTsw7JO3RGOz"
   },
   "source": [
    "<img src=\"Wikipedia-ML.png\" width=\"85%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_mAXOWi4RGO0"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XdYqkKqjRGO1"
   },
   "source": [
    "## Difference between \"Deep Learning\" and other ML techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5RhMoejtRGO1"
   },
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qVq8uprHRGO1"
   },
   "source": [
    "<img src=\"Simple-NN.png\" width=\"33%\" align=\"right\"/>\n",
    "The basic idea of a \"multilayer perceptron\" is a \"feed-forward\" artificial neural network, composed of \"neurons\" arranged in \"layers.\"  A common illustration is similar to that at right.  This idea of \"Hebbian networks\" has existed since the 1940s, but it really only became a machine learning technique with Paul Werbos' 1975 introduction of \"backpropagation\" as a means to train such networks.  Either way, the ideas are fairly old.\n",
    "\n",
    "Included in diagram is a network with 4 layers and 12 connections (i.e. \"parameters\").  If it were \"fully connected\" the diagram would have 16 parameters. What makes a particular trained network special is the set of \"weights\" in the connections, illustrated and commonly named as subscripted $w$ values.\n",
    "\n",
    "For many decades after neural networks were known, they remained a minor area of interest.  Usually a variety of other techniques rooted in statistics and linear algebra were more effective in solving problems of classification, regression, and clustering.\n",
    "\n",
    "Image credit: [\"Feedforward Neural Networks\", John McGonagle and yushi 21](https://brilliant.org/wiki/feedforward-neural-networks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ymGgaQX2RGO2"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yr0DGqahRGO3"
   },
   "source": [
    "### \"Deep\" really just means much larger..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rC7RiKfJRGO4"
   },
   "source": [
    "In the last decade or less, neural networks—mathematically not much different from those described in the 1940s—grew much larger.  For example, the extremely power Inception v3 image classifier consists of approximately 23.8 million parameters across about 140 layers.  Layers generally each have many more neurons than the half-dozen or fewer shown in textbook illustrations like the one shown above.  Scikit-learn has basic neural network techniques, but their use is mostly for the uses that made sense more than five years ago.\n",
    "\n",
    "Classic \"fully connected\" layers make up only a small number of those used. More than anything else, the effect and reason for this is to limit the combinatorial explosion of connections, limiting the parameters to **only** 24 million. \n",
    "<img src=\"inceptionv3.png\"/>\n",
    "Image credit: [\"Advanced Guide to Inception v3 on Cloud TPU\" (Google)](https://cloud.google.com/tpu/docs/inception-v3-advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pst-Db_hRGO4"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MKbDifnhRGO4"
   },
   "source": [
    "## Other tools used for deep learning and computational requirements (GPU, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAlcV_P-RGO5"
   },
   "source": [
    "Training modern deep neural networks requires large clusters of machines, ideally consisting of high-performance GPUs or even more specialized hardware like Google's Tensor Processing Unit (TPU).  Competitive designs are impractical—or at least time consuming—to train on ordinary desktop systems or single servers.  Evaluating a trained model is much cheaper, however, and running a classifier on ordinary higher-end CPUs is perfectly fine.\n",
    "\n",
    "In contrast, the machine learning algorithms provided by Scikit-learn are generally easily trainable on ordinary computers, albeit not always entirely fast to train on typical machines.\n",
    "\n",
    "Some popular tools for programming deep neural networks include the below.  Python dominates in this space.\n",
    "\n",
    "For Python: \n",
    "* Tensorflow\n",
    "* Theano\n",
    "* Keras\n",
    "* Chainer\n",
    "* PyTorch\n",
    "\n",
    "For other programming languages: \n",
    "* Torch\n",
    "* Cafe2\n",
    "* Microsoft Cognitive Toolkit (CNTK)\n",
    "* Deep Learning 4J\n",
    "* Apache MXnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KhD7GS17RGO7"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k0_KUt3ZRGO7"
   },
   "source": [
    "# Techniques "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vp2tVu4fRGO9"
   },
   "source": [
    "<img alt=\"Classification versus regression\" src=\"http://scikit-learn.org/stable/_static/ml_map.png\" width=\"80%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IqR4Se41RGO9"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3tVxETF1RGO-"
   },
   "source": [
    "> **\"If you torture the data enough, nature will always confess.\"** –Ronald Coase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXZ3ku_URGO_"
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OSm8XfFERGO_"
   },
   "source": [
    "Classification is a type of *supervised* learning in which the targets for a prediction are a set of categorical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t6-n5eKuRGPA"
   },
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "seERGqinRGPA"
   },
   "source": [
    "Regression is a type of *supervised* learning in which the targets for a prediction are quantitative or continuous values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUjhw2qbRGPB"
   },
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9a0RyKaYRGPB"
   },
   "source": [
    "Clustering is a type of *unsupervised* learning where you want to identify similarities among collections of items without an *a prior* classification scheme.  You may or may not have an *a priori* about the **number** of categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zkzpqMleRGPC"
   },
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0MLcS29aRGPD"
   },
   "source": [
    "Dimensionality reduction is most often a technique used to assist with other techniques.  By reducing a large number of features to relatively few features; very often other techniques are more successful relative to these transformed synthetic features.  Sometimes the dimensionality reduction itself is sufficient to identify the \"main gist\" or your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N8BNwmBuRGPE"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZi4aZs6RGPE"
   },
   "source": [
    "# More Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_xhia1TaRGPF"
   },
   "source": [
    "While the four techniques listed above are usually your ultimate goal in a machine learning design, some background concepts and/or techniques are often invaluable in getting there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QM77-T2hRGPG"
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHUuB-cvRGPG"
   },
   "source": [
    "Very often, the \"features\" we are given in our original data are not those that will prove most useful in our final analysis.  It is often necessary to identify \"the data inside the data.\"  Sometimes feature engineering can be as simple as normalizing the distribution of values.  Other times it can involve creating synthetic features out of two or more raw features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XDsEN72eRGPJ"
   },
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eIBm6vhpRGPL"
   },
   "source": [
    "Often, the features you have in your raw data contain some features with little to no predictive or analytic value.  Identifying and excluding irrelevant features often improves the quality of a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oq3mJTWBRGPL"
   },
   "source": [
    "## Categorical vs. Ordinal vs. Continuous variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WT0Jfl2xRGPL"
   },
   "source": [
    "Features come in one of three basic types.  \n",
    "\n",
    "Some are *categorical* (also called *nominal*): A discrete set of values that a feature may assume, often named by words or codes (but sometimes confusingly as integers where an order may be misleadingly implied).  \n",
    "\n",
    "Some are *ordinal*: There is a scale from low to high in the data values, but the spacing in the data may have little to no relationship to the underlying phenomenon.  For example, while an airline or credit card \"reward program\" might have levels of Gold/Silver/Platinum/Diamond, there is probably no real sense in which Diamond is \"4 times as much\" as Gold, even though they are encoded as 1-4.\n",
    "\n",
    "Some are *continuous* or *quantitative*: Some quantity is actually measured such that a number represents the amount of it.  The *distribution* of these measurements is likely not to be uniform and linear (in which case scaling might be relevant), but there is a real thing being measured.  Measurements might be quantized for continuous variables, but that does not necessarily make them ordinal instead.  For example, we might measure annual rainfall in each town only to the nearest inch, and hence have integers for that feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DyEOXTsORGPL"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mpq6b8_0RGPN"
   },
   "source": [
    "# Yet more techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6fyvHpw7RGPO"
   },
   "source": [
    "Most of the concepts just discussed apply to statistics more generally.  The next few concepts are more specific to *machine* learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J4QIU1BfRGPO"
   },
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BQqJBEa_RGPQ"
   },
   "source": [
    "For many machine learning algorithms, including neural networks, it is more useful to have a categorical feature with N possible values encoded as N features, each taking a binary value.  Several tools, including a couple functions in *scikit-learn* will transform raw datasets into this format.  Obviously, by encoding this way, dimensionality is increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kxp4iA_ARGPR"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DaZ4EBIlRGPS"
   },
   "source": [
    "The notion of *parameters* was introduced to define the way in which a model was trained.  For neural networks, parameters are the weights of all the connections between the neurons.  But in other models a similar parameterization exists.  For example, in a basic linear regression, the coefficients in each dimension are parameters of the trained/fitted model.\n",
    "\n",
    "However, many algorithms used in machine learning take \"hyperparameters\" that tune how the training itself occurs.  These may be cutoff values where a \"good enough\" estimate is obtained, for example.  Or there may be hidden terms in an underlying equation that can be set.  Or an algorithm may actually be a family of closely related algorithms, and a hyperparameter chooses among them.  Models in *scikit-learn* typically have a number of hyperparameters to set before they are trained (with \"sensible\" defaults when you do not specify)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qdzZNbzXRGPT"
   },
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rxy0o3UwRGPT"
   },
   "source": [
    "While *scikit-learn* usually provides \"sensible\" defaults for hyperparameters, there is often a great deal of domain and dataset specificity for which hyperparameters are most effective.  An API is provided to search across the combinatorial space of hyperparameter values and evaluate each collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G8Fmysn_RGPU"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "07lVX0UnRGPV"
   },
   "source": [
    "# Example: Machines Learning About Humans Learning About Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "roYqDCoIRGPX",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "I had the great honor and pleasure of presenting the first tutorial at [AnacondaCON 2018](https://anacondacon.io/), on machine learning with scikit-learn.  I spoke to a full room of about 120 enthusiastic, and aspiring, data scientists.  \n",
    "\n",
    "The attendees of my session were a very nice group of learners and experts.  But I decided I wanted to know even more about these people than I could find by looking at their faces and responding to their questions.  So I asked them to complete a slightly whimsical form at about 3 hours into my tutorial.  Just who are these people, and what can scikit-learn tell us about which of them benefitted most from the tutorial?\n",
    "\n",
    "In the interest open data science, the collection of answers given by attendees is available under a [CC-BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/legalcode) license.  Please credit it as \"&copy; Anaconda Inc. 2018\" if you use the anonymized data, [available as a CSV file](https://goo.gl/WgTQMX).  If you wish to code along with the rest of this notebook, save it locally as `Learning about Humans learning ML.csv` (or adjust your code as needed).\n",
    "\n",
    "The attendees of this webinar, or those later viewing this notebook, are well described as:\n",
    "\n",
    "> **\"Humans learning about machines learning about humans learning about machine learning.\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FKZswiecRGPX"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vaas82k4RGPX"
   },
   "source": [
    "## The whimsical dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KF9kNA6XRGPY"
   },
   "source": [
    "Data never arrives at the workstation of a data scientist quite clean, no matter how much validation is attempted in the collection process.  The respondent data is no exception.  Using the familiar facilities in Pandas, we can improve the initial data before applying scikit-learn to it.  In particular, I failed to validate the field \"`Years of post-secondary education (e.g. BA=4; Ph.D.=10)`\" as a required integer.  Also, the \"`Timestamps`\" added by the form interface are gratuitous for these purposes—they are all within a couple minutes of each other, but the order or spacing is unlikely to have any value to our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "trDVykQQRGPZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YQovH3bzRGPf"
   },
   "outputs": [],
   "source": [
    "fname = \"Learning about Humans learning ML.csv\"\n",
    "humans = pd.read_csv(fname)\n",
    "\n",
    "humans.drop('Timestamp', axis=1, inplace=True)\n",
    "humans['Education'] = (humans[\n",
    "    'Years of post-secondary education (e.g. BA=4; Ph.D.=10)']\n",
    "                       .str.replace(r'.*=','')\n",
    "                       .astype(int))\n",
    "humans.drop('Years of post-secondary education (e.g. BA=4; Ph.D.=10)', \n",
    "            axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tSRu_AYTRGPg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KsI_E0WnRGPh"
   },
   "source": [
    "## Eyballing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xSBrVk4WRGPi"
   },
   "source": [
    "When you read a dataset, it is almost always useful to take a quick look at part of it to get a \"feel\" for the data.  If the dataset can be read as a Pandas DataFrame, overview inspection is particularly easy and friendly.\n",
    "\n",
    "> **\"90% of the time spent doing data analysis is doing data cleanup.\"** –Every Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kPvyoiBZRGPj",
    "outputId": "eb054dca-7fd6-4886-80a3-383ef310b461"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Favorite programming language</th>\n",
       "      <th>Favorite Monty Python movie</th>\n",
       "      <th>Years of Python experience</th>\n",
       "      <th>Have used Scikit-learn</th>\n",
       "      <th>Age</th>\n",
       "      <th>In the Terminator franchise, did you root for the humans or the machines?</th>\n",
       "      <th>Which is the better game?</th>\n",
       "      <th>How successful has this tutorial been so far?</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python</td>\n",
       "      <td>Monty Python's Life of Brian</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Yep!</td>\n",
       "      <td>53</td>\n",
       "      <td>Skynet is a WINNER!</td>\n",
       "      <td>Tic-tac-toe (Br. Eng. \"noughts and crosses\")</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python</td>\n",
       "      <td>Monty Python and the Holy Grail</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Yep!</td>\n",
       "      <td>33</td>\n",
       "      <td>Team Humans!</td>\n",
       "      <td>Chess</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python</td>\n",
       "      <td>Monty Python and the Holy Grail</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yep!</td>\n",
       "      <td>31</td>\n",
       "      <td>Team Humans!</td>\n",
       "      <td>Chess</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python</td>\n",
       "      <td>Monty Python and the Holy Grail</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Yep!</td>\n",
       "      <td>60</td>\n",
       "      <td>Team Humans!</td>\n",
       "      <td>Tic-tac-toe (Br. Eng. \"noughts and crosses\")</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Favorite programming language      Favorite Monty Python movie  \\\n",
       "0                        Python     Monty Python's Life of Brian   \n",
       "1                        Python  Monty Python and the Holy Grail   \n",
       "2                        Python  Monty Python and the Holy Grail   \n",
       "3                        Python  Monty Python and the Holy Grail   \n",
       "\n",
       "   Years of Python experience Have used Scikit-learn  Age  \\\n",
       "0                        20.0                   Yep!   53   \n",
       "1                         4.0                   Yep!   33   \n",
       "2                         1.0                   Yep!   31   \n",
       "3                        12.0                   Yep!   60   \n",
       "\n",
       "  In the Terminator franchise, did you root for the humans or the machines?  \\\n",
       "0                                Skynet is a WINNER!                          \n",
       "1                                       Team Humans!                          \n",
       "2                                       Team Humans!                          \n",
       "3                                       Team Humans!                          \n",
       "\n",
       "                      Which is the better game?  \\\n",
       "0  Tic-tac-toe (Br. Eng. \"noughts and crosses\")   \n",
       "1                                         Chess   \n",
       "2                                         Chess   \n",
       "3  Tic-tac-toe (Br. Eng. \"noughts and crosses\")   \n",
       "\n",
       "   How successful has this tutorial been so far?  Education  \n",
       "0                                              8         12  \n",
       "1                                              9          5  \n",
       "2                                             10         10  \n",
       "3                                              6         10  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humans.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pb4_Vo-mRGPo"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NZscz5KXRGPp"
   },
   "source": [
    "In terms of metadata *about* the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DsC2FnZWRGPs",
    "outputId": "bde3299b-dced-4978-ee57-5515e13100e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Favorite programming language</th>\n",
       "      <th>Favorite Monty Python movie</th>\n",
       "      <th>Years of Python experience</th>\n",
       "      <th>Have used Scikit-learn</th>\n",
       "      <th>Age</th>\n",
       "      <th>In the Terminator franchise, did you root for the humans or the machines?</th>\n",
       "      <th>Which is the better game?</th>\n",
       "      <th>How successful has this tutorial been so far?</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>116</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>116.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Python</td>\n",
       "      <td>Monty Python and the Holy Grail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yep!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Team Humans!</td>\n",
       "      <td>Chess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>94</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.195690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.586207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.051724</td>\n",
       "      <td>6.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.136187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.260644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.229622</td>\n",
       "      <td>3.467303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Favorite programming language      Favorite Monty Python movie  \\\n",
       "count                            116                              116   \n",
       "unique                             7                                6   \n",
       "top                           Python  Monty Python and the Holy Grail   \n",
       "freq                              94                               57   \n",
       "mean                             NaN                              NaN   \n",
       "std                              NaN                              NaN   \n",
       "min                              NaN                              NaN   \n",
       "25%                              NaN                              NaN   \n",
       "50%                              NaN                              NaN   \n",
       "75%                              NaN                              NaN   \n",
       "max                              NaN                              NaN   \n",
       "\n",
       "        Years of Python experience Have used Scikit-learn         Age  \\\n",
       "count                   116.000000                    116  116.000000   \n",
       "unique                         NaN                      2         NaN   \n",
       "top                            NaN                   Yep!         NaN   \n",
       "freq                           NaN                     80         NaN   \n",
       "mean                      4.195690                    NaN   36.586207   \n",
       "std                       5.136187                    NaN   13.260644   \n",
       "min                       0.000000                    NaN    3.000000   \n",
       "25%                       1.000000                    NaN   28.000000   \n",
       "50%                       3.000000                    NaN   34.000000   \n",
       "75%                       5.000000                    NaN   43.250000   \n",
       "max                      27.000000                    NaN   99.000000   \n",
       "\n",
       "       In the Terminator franchise, did you root for the humans or the machines?  \\\n",
       "count                                                 116                          \n",
       "unique                                                  2                          \n",
       "top                                          Team Humans!                          \n",
       "freq                                                   88                          \n",
       "mean                                                  NaN                          \n",
       "std                                                   NaN                          \n",
       "min                                                   NaN                          \n",
       "25%                                                   NaN                          \n",
       "50%                                                   NaN                          \n",
       "75%                                                   NaN                          \n",
       "max                                                   NaN                          \n",
       "\n",
       "       Which is the better game?  \\\n",
       "count                        116   \n",
       "unique                         4   \n",
       "top                        Chess   \n",
       "freq                          69   \n",
       "mean                         NaN   \n",
       "std                          NaN   \n",
       "min                          NaN   \n",
       "25%                          NaN   \n",
       "50%                          NaN   \n",
       "75%                          NaN   \n",
       "max                          NaN   \n",
       "\n",
       "        How successful has this tutorial been so far?   Education  \n",
       "count                                      116.000000  116.000000  \n",
       "unique                                            NaN         NaN  \n",
       "top                                               NaN         NaN  \n",
       "freq                                              NaN         NaN  \n",
       "mean                                         7.051724    6.172414  \n",
       "std                                          2.229622    3.467303  \n",
       "min                                          1.000000  -10.000000  \n",
       "25%                                          5.000000    4.000000  \n",
       "50%                                          8.000000    6.000000  \n",
       "75%                                          9.000000    8.000000  \n",
       "max                                         10.000000   23.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humans.describe(include=['object', 'int', 'float'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_M3qWldORGPv"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wlUwwfpqRGPw"
   },
   "source": [
    "## Data cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "owYergB2RGPw"
   },
   "source": [
    "You can look into other features of the data yourself, but in the summary view a few data quality issues jump out.  This is—again—almost universal to real world datasets.  It seems dubious that two 3 year-olds were in attendance.  Perhaps a couple 30-somethings mistyped entering their ages.  A 99 year-old is possible, but seems more likely to be a placeholder value used by some respondent.  While the description of what is meant by the integer \"Education\" was probably underspecified, it still feels like the -10 years of education is more likely to be a data entry problem than an intended indicator.\n",
    "\n",
    "But the data we have is the data we must analyze.\n",
    "\n",
    "Before we go further, it is usually a good idea to use [one-hot encoding](https://en.wikipedia.org/wiki/One-hot) of categorical data for machine learning purposes.  Most likely this makes less difference for the decision tree and random forest classifiers used in this presentation than it might for other classifiers and regressors, but it rarely hurts.  In this notebook, the encoding is performed with [`pandas.get_dummies()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html), but you could equally use [`sklearn.preprocessing.LabelBinarizer`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer) to accomplish the same goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VQBxj_cRRGPw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Years of Python experience',\n",
       " 'Age',\n",
       " 'How successful has this tutorial been so far?',\n",
       " 'Education',\n",
       " 'Favorite programming language_C++',\n",
       " 'Favorite programming language_JavaScript',\n",
       " 'Favorite programming language_MATLAB',\n",
       " 'Favorite programming language_Python',\n",
       " 'Favorite programming language_R',\n",
       " 'Favorite programming language_Scala',\n",
       " 'Favorite programming language_Whitespace',\n",
       " 'Favorite Monty Python movie_And Now for Something Completely Different',\n",
       " 'Favorite Monty Python movie_Monty Python Live at the Hollywood Bowl',\n",
       " 'Favorite Monty Python movie_Monty Python and the Holy Grail',\n",
       " \"Favorite Monty Python movie_Monty Python's Life of Brian\",\n",
       " \"Favorite Monty Python movie_Monty Python's The Meaning of Life\",\n",
       " 'Favorite Monty Python movie_Time Bandits',\n",
       " 'Have used Scikit-learn_Nope.',\n",
       " 'Have used Scikit-learn_Yep!',\n",
       " 'In the Terminator franchise, did you root for the humans or the machines?_Skynet is a WINNER!',\n",
       " 'In the Terminator franchise, did you root for the humans or the machines?_Team Humans!',\n",
       " 'Which is the better game?_Chess',\n",
       " 'Which is the better game?_Go',\n",
       " 'Which is the better game?_Longing for the sweet release of death',\n",
       " 'Which is the better game?_Tic-tac-toe (Br. Eng. \"noughts and crosses\")']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_dummies = pd.get_dummies(humans)\n",
    "list(human_dummies.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9uwUbfOGRGP1"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-MHVlSGwRGP1"
   },
   "source": [
    "# Classification: Choosing features and a target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bGK7k3sZRGP1"
   },
   "source": [
    "It is time to use scikit-learn to model the respondents.  In particular, we would like to know whether other features of attendees are a good predictor of how successful they found the tutorial.  A very common pattern you will see in machine learning based on starting DataFrames is to drop one column for the `X` features, and keep that one for the `y` target.\n",
    "\n",
    "In my analysis, I felt a binary measure of success was more relevant than a scalar measure initially collected as a 1-10 scale.  Moreover, if the target is simplified this way, it becomes appropriate to use a **classification** algorithm as opposed to a **regression** algorithm.  It would be a mistake to treat the 1-10 scale as a categorical consisting of 10 independent labels—there is something inherently ordinal about these labels, although *scikit-learn* will happily calculate models as if there is not.  This is a place where subject matter judgement is needed by a data scientist.\n",
    "\n",
    "You will have noticed by the summary data giving mean and median of success scores that `>=8` will approximately evenly divide the data into \"Yes\" and \"No\" categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQXIjJzRRGP5"
   },
   "outputs": [],
   "source": [
    "X = human_dummies.drop(\"How successful has this tutorial been so far?\", axis=1)\n",
    "y = human_dummies[\"How successful has this tutorial been so far?\"] >= 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8RJrj_4ARGP8"
   },
   "source": [
    "## Conventional names and shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LoZ08upeRGP8"
   },
   "source": [
    "In almost all machine learning discussions, you will see the names capital-X and lowercase-y for the feature set and the target.  The idea here is that the capital stands for the *independent variables*, but in general one expects there to be multiple such feature variables.  The target consists of just one *dependent variable*, and hence its lowercase.  The feature set and the target will always have the same number of rows.\n",
    "\n",
    "Using X and y to distinguish independent and dependent variables is widespread in many areas of mathematics.  Moreover, you will often see the features within X named x<sub>1</sub>, x<sub>2</sub>, x<sub>3</sub>, and so on in more academic texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pN1svNMNRGP-"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5HZzBYQRGP-",
    "outputId": "3f1cecf2-dc31-4c78-dcff-08d340b54c6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1     True\n",
       "2     True\n",
       "3    False\n",
       "4     True\n",
       "Name: How successful has this tutorial been so far?, dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_eyVDlBZRGQB",
    "outputId": "b4ae8aaa-0bab-4be0-b09d-2bee844f96c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Years of Python experience</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Favorite programming language_C++</th>\n",
       "      <th>Favorite programming language_JavaScript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Years of Python experience  Age  Education  \\\n",
       "0                        20.0   53         12   \n",
       "1                         4.0   33          5   \n",
       "2                         1.0   31         10   \n",
       "3                        12.0   60         10   \n",
       "4                         7.0   48          6   \n",
       "\n",
       "   Favorite programming language_C++  Favorite programming language_JavaScript  \n",
       "0                                  0                                         0  \n",
       "1                                  0                                         0  \n",
       "2                                  0                                         0  \n",
       "3                                  0                                         0  \n",
       "4                                  0                                         0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[:5,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qCEBP_27RGQH"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ln8DU_vMRGQI"
   },
   "source": [
    "# Train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h6Tqtk1uRGQJ"
   },
   "source": [
    "While using [sklearn.model_selection.StratifiedKFold](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) is a more rigorous way of evaluating a model, for quick-and-dirty experimentation, using `train_test_split` is usually the easiest approach.  In either case, the basic principle is that you want to avoid *overfitting* by training on different data than you use to test your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D4a8JwXLRGQK",
    "outputId": "fc171858-2227-4baa-a4ff-13866bf0cc1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features/target: (87, 24) (87,)\n",
      "Testing features/target: (29, 24) (29,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(\"Training features/target:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing features/target:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5wA5kyjjRGQN"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-xbKD8X1RGQO"
   },
   "source": [
    "## Choosing an algorithm: Decision Trees and Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kaa6faDcRGQO"
   },
   "source": [
    "An interesting thing happened in trying a few models out.  While `RandomForestClassifier` is incredibly powerful, and very often produces the most accurate predictions among all classifiers, for this particular data a single `DecisionTreeClassifer` does better.  Attendees might want to think about why this turns out to be true and/or experiment with hyperparameters to find a more definite explanation; other classifiers might perform better still also, of course.\n",
    "\n",
    "I will note that choosing the best `max_depth` for decision tree family algorithms is largely a matter of trial and error.  You can search the space in a nice high level API using [sklearn.model_selection.GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), but it often suffices to use a basic Python loop like:\n",
    "\n",
    "```python\n",
    "for n in range(1,20):\n",
    "    tree = DecisionTreeClassifier(max_depth=n)\n",
    "    tree.fit(X_train, y_train)\n",
    "    print(n, tree.score(X_test, y_test))\n",
    "```    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXV86xYgRGQP",
    "outputId": "c43a6c90-c329-4e16-b8c3-ca6798f69dfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51724137931034486"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_z-WfugkRGQU",
    "outputId": "a0de5fac-c51a-4fe1-f290-b20edf3e2248"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58620689655172409"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=7, random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CXdnKprCRGQY"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-M4JYWzcRGQZ"
   },
   "source": [
    "# Feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DShGyn9URGQZ"
   },
   "source": [
    "Best practice in machine learning is to keep training and testing sets separate.  In the end, with sufficiently large datasets, it makes little difference in the trained model parameters whether or how train/test observations are separated.  But this is a small dataset, and also reflects a somewhat unique event (many students will learn about machine learning through many channels, but this particular tutorial, with a particular instructor, at a particular conference, will not necessarily generalize to all those channels).\n",
    "\n",
    "Therefore, in order to see simply what is the \"best possible\" decision tree for this dataset, I deliberately overfit by including all the observations in the model.  \n",
    "\n",
    "*Note that the feature importances identified by this classifier are not *necessarily* of the same order or ratios as would be produced by other classifiers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CggXLD2cRGQb",
    "outputId": "da53b02e-2a52-4ce0-973a-2ba966ce81d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81034482758620685"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=7, random_state=0)\n",
    "tree.fit(X, y)\n",
    "tree.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vUOii3rIRGQf",
    "outputId": "1e540f4e-c921-4ec7-c1de-47f9fbea8d76"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABeUAAAGfCAYAAADRULlHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nykuSJEmSJEmS1Cf/H5Iq4HpbTfqqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdb1f8962e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "pd.Series(tree.feature_importances_, index=X.columns).plot.barh(figsize=(18,7));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XXQOItyERGQj"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LA5EIkfiRGQk"
   },
   "source": [
    "# Cut points in a Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3jfNC-tKRGQl"
   },
   "source": [
    "As well as seeing what features are most important in this trained model, we can use a lovely utility method in `sklearn.tree` to display the entire tree and its decision cuts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fA0OfkeZRGQm",
    "outputId": "f42fa473-4232-4a9c-98fb-8b85df3ca1bc"
   },
   "source": [
    "```python\n",
    "from sklearn.tree import export_graphviz\n",
    "import sys, subprocess\n",
    "export_graphviz(tree, feature_names=X.columns, class_names=['failure','success'],\n",
    "                out_file='ml-good.dot', impurity=False, filled=True)\n",
    "subprocess.check_call([sys.prefix+'/bin/dot','-Tpng','ml-good.dot',\n",
    "                       '-o','ml-good.png'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fA0OfkeZRGQm",
    "outputId": "f42fa473-4232-4a9c-98fb-8b85df3ca1bc"
   },
   "source": [
    "![Cut points](ml-good.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cMYM-cN1RGQq"
   },
   "source": [
    "In the diagram, blue branches reflect those respondents who found the tutorial more successful, and orange branches those who found it less so.  The saturation of the displayed boxes reflects the strength of that decision branch.\n",
    "\n",
    "As seems obvious in retrospect, the fans of [_And Now for Something Completely Different_](https://en.wikipedia.org/wiki/And_Now_for_Something_Completely_Different) really did not like my tutorial very much.  I probably should have provided a disclaimer at the beginning of the session.  Years of Python experience is a slightly more important feature, but it follows an oddly stratified pattern wherein several different ranges of years show positive or negative effects—it's not linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IV4Vr5pZRGQr"
   },
   "source": [
    "And of course, [_Time Bandits_](https://en.wikipedia.org/wiki/Time_Bandits) was not a Monty Python film at all: it is a Terry Gilliam film that happened to cast a number of Monty Python cast members.  What on earth **were** those respondents thinking?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klUkUwRnRGQs"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ql3wN7JKRGQu"
   },
   "source": [
    "# Quick comparison of many classifiers in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pT4GI-W3RGQu"
   },
   "source": [
    "> **\"The first 90 percent of the code accounts for the first 90 percent of the development time. The remaining 10 percent of the code accounts for the other 90 percent of the development time.\"** –Tom Cargill, Bell Labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4dBUYPWDRGQv"
   },
   "source": [
    "Having done the 90% of our work that was needed for data cleanup, the next 90% can be spent on model selection.  Better hyper-parameters than those chosen below (mostly defaults) are likely to identify better fits.  Moreover, the few classifiers listed are by no means all of those in *scikit-learn*.\n",
    "\n",
    "This code is mostly based on the Scikit-learn [Classifier Comparison](http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html).\n",
    "\n",
    "> Code source: Gaël Varoquaux & Andreas Müller<br/>\n",
    "> Modified for documentation by Jaques Grobler<br/>\n",
    "> License: BSD 3 clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S21EOj91RGQw"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classifiers = {\n",
    "    \"KNN(3)\"       : KNeighborsClassifier(3), \n",
    "    \"Linear SVM\"   : SVC(kernel=\"linear\"), \n",
    "    \"RBF SVM\"      : SVC(gamma=2, C=1), \n",
    "    \"Gaussian Proc\": GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=7), \n",
    "    \"Random Forest\": RandomForestClassifier(max_depth=7, n_estimators=10, max_features=4), \n",
    "    \"Neural Net\"   : MLPClassifier(alpha=1), \n",
    "    \"AdaBoost\"     : AdaBoostClassifier(),\n",
    "    \"Naive Bayes\"  : GaussianNB(), \n",
    "    \"QDA\"          : QuadraticDiscriminantAnalysis()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B103d05URGQx",
    "outputId": "3a153404-a2ca-4a61-fcf0-794aed197baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN(3)         | score = 0.517\n",
      "Linear SVM     | score = 0.621\n",
      "RBF SVM        | score = 0.586\n",
      "Gaussian Proc  | score = 0.483\n",
      "Decision Tree  | score = 0.517\n",
      "Random Forest  | score = 0.621\n",
      "Neural Net     | score = 0.586\n",
      "AdaBoost       | score = 0.552\n",
      "Naive Bayes    | score = 0.655\n",
      "QDA            | score = 0.621\n"
     ]
    }
   ],
   "source": [
    "for name, classifier in classifiers.items():\n",
    "    classifier.fit(X_train, y_train)\n",
    "    score = classifier.score(X_test, y_test)\n",
    "    print(\"{:<15}| score = {:.3f}\".format(name, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f2_8VlyBRGQ-"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_GjWBIJgRGQ_"
   },
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G9guRZ08RGRC"
   },
   "source": [
    "For a regression, we want a range of target values, not a binary category. Having one-hot encoded binary features with a target that is more ordinal than continuous is close to the worst case for using a regression.  It's time to move away from the \"Learning about Humans learning ML\" dataset. We will use a well-known example dataset that is included with *scikit-learn* for this next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6yInBJGQRGRC"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gkFq0rMyRGRD"
   },
   "source": [
    "## Sample datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ePOeUBCNRGRE"
   },
   "source": [
    "A number of sample datasets are included with scikit-learn, either already bundled with a `load_*()` function for the smaller ones or with a `fetch_*()` function for the larger ones that can be obtained online.  The `make_*()` functions create synthetic datasets with some randomness in their generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCeNguCJRGRF",
    "outputId": "4af093c9-7b0e-41aa-a8fc-07a2d10dc666"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base',\n",
       " 'california_housing',\n",
       " 'clear_data_home',\n",
       " 'covtype',\n",
       " 'dump_svmlight_file',\n",
       " 'fetch_20newsgroups',\n",
       " 'fetch_20newsgroups_vectorized',\n",
       " 'fetch_california_housing',\n",
       " 'fetch_covtype',\n",
       " 'fetch_kddcup99',\n",
       " 'fetch_lfw_pairs',\n",
       " 'fetch_lfw_people',\n",
       " 'fetch_mldata',\n",
       " 'fetch_olivetti_faces',\n",
       " 'fetch_rcv1',\n",
       " 'fetch_species_distributions',\n",
       " 'get_data_home',\n",
       " 'kddcup99',\n",
       " 'lfw',\n",
       " 'load_boston',\n",
       " 'load_breast_cancer',\n",
       " 'load_diabetes',\n",
       " 'load_digits',\n",
       " 'load_files',\n",
       " 'load_iris',\n",
       " 'load_linnerud',\n",
       " 'load_mlcomp',\n",
       " 'load_sample_image',\n",
       " 'load_sample_images',\n",
       " 'load_svmlight_file',\n",
       " 'load_svmlight_files',\n",
       " 'load_wine',\n",
       " 'make_biclusters',\n",
       " 'make_blobs',\n",
       " 'make_checkerboard',\n",
       " 'make_circles',\n",
       " 'make_classification',\n",
       " 'make_friedman1',\n",
       " 'make_friedman2',\n",
       " 'make_friedman3',\n",
       " 'make_gaussian_quantiles',\n",
       " 'make_hastie_10_2',\n",
       " 'make_low_rank_matrix',\n",
       " 'make_moons',\n",
       " 'make_multilabel_classification',\n",
       " 'make_regression',\n",
       " 'make_s_curve',\n",
       " 'make_sparse_coded_signal',\n",
       " 'make_sparse_spd_matrix',\n",
       " 'make_sparse_uncorrelated',\n",
       " 'make_spd_matrix',\n",
       " 'make_swiss_roll',\n",
       " 'mlcomp',\n",
       " 'mldata',\n",
       " 'mldata_filename',\n",
       " 'olivetti_faces',\n",
       " 'rcv1',\n",
       " 'samples_generator',\n",
       " 'species_distributions',\n",
       " 'svmlight_format',\n",
       " 'twenty_newsgroups']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "[attr for attr in dir(datasets) if not attr.startswith('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZoWeKZFlRGRH"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x6GYAL3tRGRI"
   },
   "source": [
    "## Boston Housing Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q0KkO0L_RGRJ"
   },
   "source": [
    "The Boston House Prices dataset contains a nice mixture of data.  Most of it is continuous, a little bit is ordinal, and just one feature is a binary category.  This contains a smallish number of rows, but is sufficient for illustration.  The specific values you will see—especially in the house prices target—will seem quaintly 1970s; those who know Boston better will find that neighborhood demographics have changed in other aspects also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BupS6sgtRGRJ",
    "outputId": "98c91027-2887-4e26-b969-335813d1944c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "boston = datasets.load_boston()\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kDNo4Cg0RGRL"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q7FOAYcARGRM"
   },
   "source": [
    "## Working with the example datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0eapasHiRGRN",
    "outputId": "b29a5d4e-5d9c-4365-c763-cfecbb2dc3e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample datasets can be easily converted to Pandas/Dask/PySpark DataFrames if desired\n",
    "boston_df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sDBnyjpyRGRQ"
   },
   "outputs": [],
   "source": [
    "# The X and y are stored in standard attributes\n",
    "X = boston.data\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2-QxzFviRGRQ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nbNbq78TRGRR"
   },
   "source": [
    "## Comparing a gaggle of regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tYL7UuC1RGRS"
   },
   "source": [
    "The metrics we use in the below code are `explained_variance_score`, `mean_absolute_error`, and `r2_score`.  Many other metrics are are available, mostly within the `sklearn.metrics` submodule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ba63iZuhRGRS"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bRst6m11RGRV"
   },
   "source": [
    "The particular regressors we choose does not reflect any deep decision.  Most are somewhat in the family of linear regression.  RANSAC is tried because it is meant to be more resilient against outliers in data.  The are *sometimes* more strongly predictive and generic linear regression.  One of several Guassian techniques is shown as an example—it behaves worthlessly for this example, at least without hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r3G5AMuXRGRV",
    "outputId": "58dc2943-63c0-4896-fe05-973016233e8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "\tExplained variance: 0.590190680164\n",
      "\tMean absolute error: 4.00267178836\n",
      "\tR2 score: 0.590177393332\n",
      "RANSACRegressor(base_estimator=None, is_data_valid=None, is_model_valid=None,\n",
      "        loss='absolute_loss', max_skips=inf, max_trials=100,\n",
      "        min_samples=None, random_state=None, residual_metric=None,\n",
      "        residual_threshold=None, stop_n_inliers=inf, stop_probability=0.99,\n",
      "        stop_score=inf)\n",
      "\tExplained variance: 0.48663394389\n",
      "\tMean absolute error: 4.60064986047\n",
      "\tR2 score: 0.452408941537\n",
      "GaussianProcessRegressor(alpha=1e-10, copy_X_train=True, kernel=None,\n",
      "             n_restarts_optimizer=0, normalize_y=False,\n",
      "             optimizer='fmin_l_bfgs_b', random_state=None)\n",
      "\tExplained variance: 0.00202131890511\n",
      "\tMean absolute error: 22.523643045\n",
      "\tR2 score: -6.00742150594\n",
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='manhattan',\n",
      "          metric_params=None, n_jobs=1, n_neighbors=9, p=2,\n",
      "          weights='uniform')\n",
      "\tExplained variance: -0.0330603912946\n",
      "\tMean absolute error: 6.4511198946\n",
      "\tR2 score: -0.0331949681658\n",
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "\tExplained variance: -0.0601034216339\n",
      "\tMean absolute error: 6.83097886417\n",
      "\tR2 score: -0.0801604438784\n",
      "LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
      "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
      "     random_state=None, tol=0.0001, verbose=0)\n",
      "\tExplained variance: 0.426156715282\n",
      "\tMean absolute error: 5.13912026034\n",
      "\tR2 score: 0.412999613597\n",
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "\tExplained variance: 0.61807071211\n",
      "\tMean absolute error: 3.74651112901\n",
      "\tR2 score: 0.608190896966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "regressors = [\n",
    "    LinearRegression(), \n",
    "    RANSACRegressor(), \n",
    "    GaussianProcessRegressor(),\n",
    "    KNeighborsRegressor(n_neighbors=9, metric='manhattan'),\n",
    "    SVR(),\n",
    "    LinearSVR(),\n",
    "    SVR(kernel='linear') # Cf. LinearSVR: much slower, might be better or worse: \n",
    "]\n",
    "\n",
    "for model in regressors:\n",
    "    predictions = cross_val_predict(model, X, y, cv=10)\n",
    "    print(model)\n",
    "    print(\"\\tExplained variance:\", explained_variance_score(y, predictions))\n",
    "    print(\"\\tMean absolute error:\", mean_absolute_error(y, predictions))\n",
    "    print(\"\\tR2 score:\", r2_score(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6bwItiVzRGRX"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vFhETNwjRGRY"
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2c0DLnmmRGRY"
   },
   "source": [
    "As mentioned earlier, models in *scikit-learn* have hyperparameters that configure their behavior.  These can be set with named arguments to the class initializer and can be examined or set using attributes of the model object.  For example, the `KNeighborsRegressor` used in the list above performed terribly, but perhaps that is because it has less good hyperparameters.\n",
    "\n",
    "```\n",
    "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='manhattan',\n",
    "          metric_params=None, n_jobs=1, n_neighbors=9, p=2,\n",
    "          weights='uniform')\n",
    "\tExplained variance: -0.03306039129462701\n",
    "\tMean absolute error: 6.451119894598156\n",
    "\tR2 score: -0.03319496816578171\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2JSQ9O5RRGRY"
   },
   "source": [
    "In practice, you are more likely to start with an algorithm that does moderately well naively, then fine tune it.  In this example, we start with one that is terrible (on the specific dataset; it does well elsewhere), and are simply trying to get it to less terrible for the example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eCeV8S8XRGRY"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LIMzOusBRGRY"
   },
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uzxjeA35RGRZ"
   },
   "source": [
    "At heart a grid search is simply a number of nested loops, with the same combinatorial complexity as those loops make obvious.  If we want to search over `KNeighborsRegressor` with procedural code, we could write:\n",
    "\n",
    "```python\n",
    "for n_neighbors in [5,6,7,8,9,10,11,12]:\n",
    "    for weights in ['uniform', 'distance']\n",
    "        for metric in ['minkowski', 'chebyshev', 'manhattan']:\n",
    "            knr = KNeighborsRegressor(n_neighbors=n_neighbors, weights=weights, metric=metric)\n",
    "            knr.fit(...)\n",
    "            score = knr.score(...)\n",
    "            # ... keep track of best score and hyperparameters ...\n",
    "            # ... etc ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LTD38QvYRGRa"
   },
   "source": [
    "The preferred API in *scikit-learn* is more intuitive and provides a few convenience methods on the searched objects (mostly the same methods as models themselves, in fact)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h7WktFivRGRa"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AmK2fX-PRGRb"
   },
   "source": [
    "It looks like the best one can do with the Boston Housing dataset using `KNeighborsRegressor` remains terrible, but at least we can eliminate that technique for that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y7tiHLGMRGRb",
    "outputId": "b32841bb-d0c6-43ad-ebc1-5417036d1cc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "          weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_neighbors': [5, 6, 7, 8, 9, 10, 11, 12], 'weights': ['uniform', 'distance'], 'metric': ['minkowski', 'chebyshev', 'manhattan']},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "knr = KNeighborsRegressor()\n",
    "\n",
    "parameters = {'n_neighbors': [5,6,7,8,9,10,11,12],\n",
    "              'weights': ['uniform', 'distance'],\n",
    "              'metric': ['minkowski', 'chebyshev', 'manhattan']\n",
    "             }\n",
    "grid =  GridSearchCV(knr, parameters)\n",
    "model = grid.fit(X, y)  # Best fit over cross-product of parameter space\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vidKFU9tRGRf",
    "outputId": "f497be02-8cb1-4d28-f4c7-4791f62382cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance: -0.100945295679\n",
      "Mean absolute error: 6.69387857873\n",
      "R2 score: -0.101689752081\n"
     ]
    }
   ],
   "source": [
    "predictions = cross_val_predict(model, X, y, cv=10)\n",
    "print(\"Explained variance:\", explained_variance_score(y, predictions))\n",
    "print(\"Mean absolute error:\", mean_absolute_error(y, predictions))\n",
    "print(\"R2 score:\", r2_score(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C7hNeffkRGRh"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "emMWYYk6RGRh"
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y3xzSxg0RGRh"
   },
   "source": [
    "There are about a dozen clustering algorithms in *scikit-learn*.  Basically, the purpose of all of them is to find the \"lumps\" in a dimensional dataset where you do not have *a prior* labels.  For no special reason, we chose `SpectralClustering` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eKrwiotRRGRi"
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "spectral = cluster.SpectralClustering(\n",
    "        n_clusters=4, eigen_solver='arpack',\n",
    "        affinity=\"nearest_neighbors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vcudyE7oRGRi"
   },
   "source": [
    "The API for clustering is as close to those for other models as is feasible.  Specifically, these models also have a `.fit()` method, but one that does not need or accept targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qYTvDnzeRGRk",
    "outputId": "6fd05d79-970e-49a9-e260-ff200a47fa47"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>12.800000</td>\n",
       "      <td>15.689918</td>\n",
       "      <td>6.103088</td>\n",
       "      <td>89.835294</td>\n",
       "      <td>2.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mid_low</th>\n",
       "      <td>17.418447</td>\n",
       "      <td>11.082796</td>\n",
       "      <td>5.974233</td>\n",
       "      <td>90.011650</td>\n",
       "      <td>2.072428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mid_high</th>\n",
       "      <td>21.212500</td>\n",
       "      <td>0.894798</td>\n",
       "      <td>6.087675</td>\n",
       "      <td>82.507500</td>\n",
       "      <td>2.480024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>25.866090</td>\n",
       "      <td>0.248699</td>\n",
       "      <td>6.471142</td>\n",
       "      <td>54.576817</td>\n",
       "      <td>4.984178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price       CRIM        RM        AGE       DIS\n",
       "low       12.800000  15.689918  6.103088  89.835294  2.000068\n",
       "mid_low   17.418447  11.082796  5.974233  90.011650  2.072428\n",
       "mid_high  21.212500   0.894798  6.087675  82.507500  2.480024\n",
       "high      25.866090   0.248699  6.471142  54.576817  4.984178"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectral.fit(boston.data)\n",
    "\n",
    "# Let us do minor Pandas manipulation to view clusters in an intuitive way\n",
    "boston_df['category'] = spectral.labels_\n",
    "boston_df['price'] = boston.target\n",
    "house_clusters = boston_df.groupby('category').mean().sort_values('price')\n",
    "house_clusters.index = ['low', 'mid_low', 'mid_high', 'high']\n",
    "house_clusters[['price', 'CRIM', 'RM', 'AGE', 'DIS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sMu8a6jMRGRn"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DwwAD-qQRGRn"
   },
   "source": [
    "#  Where to go next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ev4JxblkRGRn"
   },
   "source": [
    "<img src=\"logo.png\" width=\"60%\"/>\n",
    "\n",
    "<div style=\"font-size:200%\">\n",
    "<dl>\n",
    "<dt>Explore Anaconda Enterprise:</dt>\n",
    "  <dd>https://www.anaconda.com/enterprise/</dd>\n",
    "<dt>Schedule an Anaconda Enterprise Demo:</dt>\n",
    "  <dd>ambassador@anaconda.com</dd>\n",
    "<dt>Learn about consulting, training, and support:</dt>\n",
    "  <dd>ambassador@anaconda.com</dd>\n",
    "</dl>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fiVsSqegRGRo"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GZ8CpyBURGRo"
   },
   "source": [
    "# Table of Contents\n",
    "* [Machine Learning with Scikit-learn](#Machine-Learning-with-Scikit-learn)\n",
    "* [Who am I?](#Who-am-I?)\n",
    "* [What is Anaconda?](#What-is-Anaconda?)\n",
    "* [What is *scikit-learn*?](#What-is-*scikit-learn*?)\n",
    "* [What is Machine Learning?](#What-is-Machine-Learning?)\n",
    "\t* [Difference between \"Deep Learning\" and other ML techniques](#Difference-between-\"Deep-Learning\"-and-other-ML-techniques)\n",
    "\t\t* [Neural Networks](#Neural-Networks)\n",
    "\t\t* [\"Deep\" really just means much larger...](#\"Deep\"-really-just-means-much-larger...)\n",
    "\t* [Other tools used for deep learning and computational requirements (GPU, etc)](#Other-tools-used-for-deep-learning-and-computational-requirements-%28GPU,-etc%29)\n",
    "* [Techniques](#Techniques)\n",
    "\t* [Classification](#Classification)\n",
    "\t* [Regression](#Regression)\n",
    "\t* [Clustering](#Clustering)\n",
    "\t* [Dimensionality Reduction](#Dimensionality-Reduction)\n",
    "* [More Techniques](#More-Techniques)\n",
    "\t* [Feature Engineering](#Feature-Engineering)\n",
    "\t* [Feature Selection](#Feature-Selection)\n",
    "\t* [Categorical vs. Ordinal vs. Continuous variables](#Categorical-vs.-Ordinal-vs.-Continuous-variables)\n",
    "* [Yet more techniques](#Yet-more-techniques)\n",
    "\t* [One-hot encoding](#One-hot-encoding)\n",
    "\t* [Hyperparameters](#Hyperparameters)\n",
    "\t* [Grid Search](#Grid-Search)\n",
    "* [Example: Machines Learning About Humans Learning About Machine Learning](#Example:-Machines-Learning-About-Humans-Learning-About-Machine-Learning)\n",
    "\t* [The whimsical dataset](#The-whimsical-dataset)\n",
    "\t* [Eyballing data](#Eyballing-data)\n",
    "\t* [Data cleanup](#Data-cleanup)\n",
    "* [Classification: Choosing features and a target](#Classification:-Choosing-features-and-a-target)\n",
    "\t* [Conventional names and shapes](#Conventional-names-and-shapes)\n",
    "* [Train/test split](#Train/test-split)\n",
    "\t* [Choosing an algorithm: Decision Trees and Random Forests](#Choosing-an-algorithm:-Decision-Trees-and-Random-Forests)\n",
    "* [Feature importances](#Feature-importances)\n",
    "* [Cut points in a Decision Tree](#Cut-points-in-a-Decision-Tree)\n",
    "* [Quick comparison of many classifiers in scikit-learn](#Quick-comparison-of-many-classifiers-in-scikit-learn)\n",
    "* [Regression](#Regression)\n",
    "\t* [Sample datasets](#Sample-datasets)\n",
    "\t* [Boston Housing Prices](#Boston-Housing-Prices)\n",
    "\t* [Working with the example datasets](#Working-with-the-example-datasets)\n",
    "\t* [Comparing a gaggle of regressors](#Comparing-a-gaggle-of-regressors)\n",
    "* [Hyperparameters](#Hyperparameters)\n",
    "* [Grid Search](#Grid-Search)\n",
    "* [Clustering](#Clustering)\n",
    "* [Where to go next?](#Where-to-go-next?)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ML.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "[anaconda50_py36] Python 3",
   "language": "python",
   "name": "anaconda-project-anaconda50_py36-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
